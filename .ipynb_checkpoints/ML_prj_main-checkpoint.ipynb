{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31621bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in c:\\users\\phanb\\anaconda3\\lib\\site-packages (4.5.3)\n",
      "Requirement already satisfied: torch in c:\\users\\phanb\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\phanb\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Các thư viện, package cần thiết:\n",
    "!pip install conllu\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91bc8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from conllu import parse\n",
    "from conllu import parse_incr\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb0c1449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences collected: 3323\n"
     ]
    }
   ],
   "source": [
    "# Tổng hợp dữ liệu từ file .conllu trả về một danh sách các câu.\n",
    "def load_conllu_data(data_path):\n",
    "    all_sentences = []\n",
    "    for file_name in os.listdir(data_path):\n",
    "        if file_name.endswith('.conllu'):\n",
    "            with open(os.path.join(data_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                for sentence in parse_incr(file):\n",
    "                    all_sentences.append(sentence)\n",
    "    return all_sentences\n",
    "\n",
    "data_path = './data/UD_Vietnamese-VTB'\n",
    "all_sentences = load_conllu_data(data_path)\n",
    "\n",
    "print(f\"Total sentences collected: {len(all_sentences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b6011b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7488, Tag set size: 17\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng từ vựng và tập hợp nhãn từ các câu đã đọc.\n",
    "def build_vocab(sentences):\n",
    "    word_vocab = defaultdict(lambda: len(word_vocab))\n",
    "    tag_vocab = defaultdict(lambda: len(tag_vocab))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            word = token['form']\n",
    "            tag = token['upostag']\n",
    "            word_vocab[word]\n",
    "            tag_vocab[tag]\n",
    "\n",
    "    # Đóng băng từ vựng để tránh thêm từ mới\n",
    "    word_vocab.default_factory = None\n",
    "    tag_vocab.default_factory = None\n",
    "\n",
    "    return word_vocab, tag_vocab\n",
    "\n",
    "word_vocab, tag_vocab = build_vocab(all_sentences)\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(tag_vocab)}\n",
    "\n",
    "print(f\"Vocabulary size: {len(word_vocab)}, Tag set size: {len(tag_vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "903a2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 2658, Testing data size: 665\n"
     ]
    }
   ],
   "source": [
    "#Chuyển đổi mỗi câu thành một tensor, bao gồm các từ và nhãn tương ứng.\n",
    "def sentence_to_tensor(sentence, word_vocab, tag_vocab):\n",
    "    words = [word_vocab[token['form']] for token in sentence]\n",
    "    tags = [tag_vocab[token['upostag']] for token in sentence]\n",
    "    return torch.tensor(words, dtype=torch.long), torch.tensor(tags, dtype=torch.long)\n",
    "\n",
    "sentences_tensors = [sentence_to_tensor(sentence, word_vocab, tag_vocab) for sentence in all_sentences]\n",
    "train_data, test_data = train_test_split(sentences_tensors, test_size=0.2, random_state=26)\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}, Testing data size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fde2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo hàm collate_fn tùy chỉnh để padding các tensor\n",
    "def collate_fn(batch):\n",
    "    words, tags = zip(*batch)\n",
    "    words_padded = pad_sequence(words, batch_first=True, padding_value=0)\n",
    "    tags_padded = pad_sequence(tags, batch_first=True, padding_value=-1)  # -1 cho padding\n",
    "    lengths = [len(seq) for seq in words]\n",
    "    return words_padded, tags_padded, lengths\n",
    "\n",
    "# Tạo Dataset tùy chỉnh\n",
    "class DependencyParsingDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Tạo DataLoader với hàm collate_fn tùy chỉnh\n",
    "train_dataset = DependencyParsingDataset(train_data)\n",
    "test_dataset = DependencyParsingDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a2e5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình BiLSTMParser\n",
    "class BiLSTMParser(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTMParser, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b018500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm huấn luyện mô hình\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for words, tags, lengths in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(words, lengths)\n",
    "\n",
    "            # Chuyển đổi các tensor để tính toán loss chính xác\n",
    "            outputs = outputs.view(-1, output_dim)\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, tags)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")\n",
    "        scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9136116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predicted, tags):\n",
    "    true_positives = (predicted == tags).sum().item()\n",
    "    false_positives = (predicted != tags).sum().item()\n",
    "    false_negatives = (predicted != tags).sum().item()\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fbe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9288103168918973\n",
      "Epoch 2, Loss: 0.33178286751111347\n",
      "Epoch 3, Loss: 0.18008885780970255\n",
      "Epoch 4, Loss: 0.10787290228264672\n",
      "Epoch 5, Loss: 0.06870698946572486\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình, hàm loss và optimizer\n",
    "vocab_size = len(word_vocab)\n",
    "embedding_dim = 200\n",
    "hidden_dim = 256\n",
    "output_dim = len(tag_vocab)\n",
    "\n",
    "model = BiLSTMParser(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Bỏ qua giá trị padding\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) #cập nhật learning rate tăng tính hội tụ\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "train_model(model, train_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e23d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2593, Precision: 0.4507, Recall: 0.4507, F1-score: 0.4507\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_tags = 0\n",
    "    with torch.no_grad():\n",
    "        for words, tags, lengths in test_loader:\n",
    "            outputs = model(words, lengths)\n",
    "            outputs = outputs.view(-1, output_dim)\n",
    "            tags = tags.view(-1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == tags).sum().item()\n",
    "            total_tags += tags.size(0)\n",
    "    accuracy = total_correct / total_tags\n",
    "    precision, recall, f1_score = calculate_metrics(predicted, tags)\n",
    "    return accuracy, precision, recall, f1_score\n",
    "accuracy, precision, recall, f1_score = evaluate_model(model, test_loader)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0dbe74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')  \n",
    "import matplotlib.pyplot as plt\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "values = [accuracy, precision, recall, f1_score]\n",
    "\n",
    "# Vẽ đồ thị\n",
    "plt.bar(metrics, values)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9011de88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu mẫu: Các loại thú rừng được nhốt trong bao , lồng sắt .\n",
      "                                         VERB(nhốt)                                        \n",
      "              _______________________________|________________________________________      \n",
      "         NOUN(loại)                |                NOUN(bao)                         |    \n",
      "    _________|__________           |          __________|_________                    |     \n",
      "   |                NOUN(thú)      |         |                NOUN(lồng)              |    \n",
      "   |                    |          |         |           _________|__________         |     \n",
      "DET(Các)            NOUN(rừng) AUX(được) ADP(trong)  PUNCT(,)            NOUN(sắt) PUNCT(.)\n",
      "   |                    |          |         |          |                    |        |     \n",
      "  ...                  ...        ...       ...        ...                  ...      ...   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vẽ cây\n",
    "import nltk\n",
    "from nltk import Tree\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conllu_to_nltk_tree(sentence):\n",
    "    def token_to_nltk_tree(token):\n",
    "        word = token['form']\n",
    "        head = int(token['head'])\n",
    "        deprel = token['deprel']\n",
    "        upos = token['upostag']  # Thêm nhãn từ loại (POS tag)\n",
    "        return (word, upos, head, deprel)\n",
    "\n",
    "    def build_tree(tokens):\n",
    "        root = None\n",
    "        token_dict = {token['id']: token for token in tokens}\n",
    "        children = {token['id']: [] for token in tokens}\n",
    "\n",
    "        for token in tokens:\n",
    "            head_id = token['head']\n",
    "            if head_id == 0:\n",
    "                root = token['id']\n",
    "            else:\n",
    "                children[head_id].append(token['id'])\n",
    "\n",
    "        def create_tree_node(token_id):\n",
    "            token = token_dict[token_id]\n",
    "            word, upos, _, _ = token_to_nltk_tree(token)  # Lấy thông tin từ loại (POS tag)\n",
    "            subtree = [create_tree_node(child_id) for child_id in children[token_id]]\n",
    "            return Tree(upos + \"(\" + word + \")\", subtree)  # Chèn nhãn từ loại vào cây\n",
    "\n",
    "        return create_tree_node(root)\n",
    "\n",
    "    nltk_tree = build_tree([token for token in sentence])\n",
    "    return nltk_tree\n",
    "\n",
    "# Vẽ cây cho câu đầu tiên\n",
    "import random\n",
    "example_sentence = all_sentences[random.randint(1, 1000)]\n",
    "nltk_tree = conllu_to_nltk_tree(example_sentence)\n",
    "\n",
    "print(\"Câu mẫu:\", \" \" .join([token['form'] for token in example_sentence]))\n",
    "\n",
    "# Vẽ cây\n",
    "nltk_tree.pretty_print()\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "nltk_tree.draw()\n",
    "plt.savefig(\"dependency_tree.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170a148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
